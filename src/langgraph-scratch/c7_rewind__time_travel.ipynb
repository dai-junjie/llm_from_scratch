{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22060a4",
   "metadata": {},
   "source": [
    "## 1. Rewind your graph\n",
    "\n",
    "Rewind your graph by fetching a checkpoint using the graph's get_state_history method. You can then resume execution at this previous point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872bac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daijunjie/miniconda3/envs/langchain-env/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "    api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "    model='qwen-plus-latest',\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6324596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = InMemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b7ccb3",
   "metadata": {},
   "source": [
    "## 2. Add steps\n",
    "\n",
    "Add steps to your graph. Every step will be checkpointed in its state history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb1e4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_6890d74c9e174ffc9a54b0)\n",
      " Call ID: call_6890d74c9e174ffc9a54b0\n",
      "  Args:\n",
      "    query: LangGraph tutorial and overview\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph tutorial and overview\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"title\": \"LangGraph Tutorial: What Is LangGraph and How to Use It?\", \"content\": \"LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\", \"score\": 0.85097736, \"raw_content\": null}, {\"url\": \"https://langchain-ai.github.io/langgraph/concepts/why-langgraph/\", \"title\": \"Learn LangGraph basics - Overview\", \"content\": \"LangGraph  *   - [x]  LangGraph basics   LangGraph basics   *   Learn LangGraph basics *   - [x]  LangGraph framework   LangGraph framework   *   - [x]  LangGraph Platform   LangGraph Platform   *   Learn LangGraph basics LangGraph is built for developers who want to build powerful, adaptable AI agents. *   **Reliability and controllability.** Steer agent actions with moderation checks and human-in-the-loop approvals. LangGraph persists context for long-running workflows, keeping your agents on course. *   **First-class streaming support.** With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time. 4.   Add human-in-the-loop controls In completing this series of tutorials, you will build a support chatbot in LangGraph that can: *   ✅ **Use custom state** to control its behavior \", \"score\": 0.81097376, \"raw_content\": null}], \"response_time\": 1.5}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a powerful library within the **LangChain ecosystem** designed to help developers build complex, stateful, and multi-agent AI applications by providing a structured framework for managing agent interactions and workflows.\n",
      "\n",
      "### Key Features of LangGraph:\n",
      "\n",
      "1. **Multi-Agent Coordination**  \n",
      "   LangGraph enables the coordination of multiple LLM agents or chains, allowing them to work together in a defined sequence or parallel structure. This is useful for building applications like chatbots that handle diverse user requests or complex task-solving systems.\n",
      "\n",
      "2. **State Management**  \n",
      "   It introduces the concept of **custom state**, which allows agents to maintain context across long-running workflows. This ensures reliability and helps keep agents on track during extended interactions.\n",
      "\n",
      "3. **Reliability & Control**  \n",
      "   - Supports **moderation checks** to filter or validate agent outputs.\n",
      "   - Enables **human-in-the-loop approvals**, giving developers control over critical decisions in the workflow.\n",
      "\n",
      "4. **Streaming Support**  \n",
      "   Offers **first-class streaming** of tokens and intermediate steps, providing real-time visibility into agent reasoning and actions — ideal for responsive user interfaces.\n",
      "\n",
      "5. **Visual Workflow Design**  \n",
      "   Workflows are represented as **directed graphs**, where nodes represent actions (like calling an LLM or tool) and edges define the flow of execution. This makes it easier to design, debug, and modify agent behavior.\n",
      "\n",
      "6. **Integration with LangChain**  \n",
      "   Built on top of LangChain, it seamlessly integrates with existing tools, models, and memory systems, making it easy to extend existing applications.\n",
      "\n",
      "---\n",
      "\n",
      "### Use Cases:\n",
      "- **Support Chatbots**: That route queries to specialized agents (e.g., billing, tech support).\n",
      "- **Autonomous Agents**: Capable of planning, executing tasks, and collaborating.\n",
      "- **Workflow Automation**: For processes requiring multiple steps, conditional logic, and external API calls.\n",
      "\n",
      "---\n",
      "\n",
      "### Learning Resources:\n",
      "- [**LangGraph Tutorial – DataCamp**](https://www.datacamp.com/tutorial/langgraph-tutorial): A beginner-friendly introduction to LangGraph concepts and implementation.\n",
      "- [**LangGraph Official Docs**](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/): Comprehensive guide covering basics, framework design, and platform features.\n",
      "\n",
      "Would you like a simple code example to get started with LangGraph?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"I'm learning LangGraph. \"\n",
    "                    \"Could you do some research on it for me?\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784b8267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That’s a great idea! Building an autonomous agent with **LangGraph** is a fantastic way to explore its capabilities. You can create agents that **plan, execute tasks, use tools, and even collaborate** with other agents.\n",
      "\n",
      "Here’s a quick roadmap to help you get started building your autonomous agent:\n",
      "\n",
      "---\n",
      "\n",
      "### 🚀 Step-by-Step: Build an Autonomous Agent with LangGraph\n",
      "\n",
      "#### 1. **Define the Goal**\n",
      "Decide what your agent should do. For example:\n",
      "- A **research agent** that answers questions by searching the web and summarizing results.\n",
      "- A **task manager** that breaks down goals, assigns subtasks, and tracks progress.\n",
      "- A **customer support bot** that routes issues and escalates when needed.\n",
      "\n",
      "---\n",
      "\n",
      "#### 2. **Set Up Your Environment**\n",
      "Install the required packages:\n",
      "```bash\n",
      "pip install langgraph langchain langchain-openai\n",
      "```\n",
      "\n",
      "> 💡 You’ll also need an API key from a provider like OpenAI, Anthropic, or Google.\n",
      "\n",
      "---\n",
      "\n",
      "#### 3. **Create a Simple Autonomous Agent (Example: Researcher)**\n",
      "\n",
      "```python\n",
      "from langgraph.graph import StateGraph, MessagesState\n",
      "from langchain_core.messages import HumanMessage\n",
      "from langchain_openai import ChatOpenAI\n",
      "\n",
      "# Initialize LLM\n",
      "llm = ChatOpenAI(model=\"gpt-4o\", api_key=\"your-openai-key\")\n",
      "\n",
      "# Define the agent's logic\n",
      "def research_node(state: MessagesState):\n",
      "    # Add a message to the state\n",
      "    response = llm.invoke(state[\"messages\"])\n",
      "    return {\"messages\": [response]}\n",
      "\n",
      "# Build the graph\n",
      "workflow = StateGraph(MessagesState)\n",
      "\n",
      "# Add nodes\n",
      "workflow.add_node(\"researcher\", research_node)\n",
      "\n",
      "# Set entry point\n",
      "workflow.set_entry_point(\"researcher\")\n",
      "\n",
      "# Add edges\n",
      "workflow.add_edge(\"researcher\", \"__end__\")\n",
      "\n",
      "# Compile the graph\n",
      "app = workflow.compile()\n",
      "\n",
      "# Run the agent\n",
      "result = app.invoke({\n",
      "    \"messages\": [HumanMessage(content=\"Summarize the latest AI trends in 2024\")]\n",
      "})\n",
      "\n",
      "print(result[\"messages\"][-1].content)\n",
      "```\n",
      "\n",
      "This creates a basic agent that takes a question and generates a response using an LLM.\n",
      "\n",
      "---\n",
      "\n",
      "#### 4. **Make It More Autonomous**\n",
      "Enhance your agent by adding:\n",
      "- **Tools**: Web search, database access, code execution.\n",
      "- **Memory**: Persistent state across interactions.\n",
      "- **Multiple Agents**: One for planning, one for research, one for writing.\n",
      "- **Human-in-the-loop**: Approval steps before taking action.\n",
      "\n",
      "---\n",
      "\n",
      "#### 5. **Use LangGraph Platform (Optional)**\n",
      "For advanced use cases, check out the **LangGraph Platform**:\n",
      "- [https://smith.langchain.com/langgraph](https://smith.langchain.com/langgraph)\n",
      "- Offers **hosting, monitoring, and debugging** for your agents.\n",
      "\n",
      "---\n",
      "\n",
      "### 🔧 Tips\n",
      "- Start small: Build a single-task agent first.\n",
      "- Use `MessagesState` for chat-like workflows or define **custom state** for complex logic.\n",
      "- Stream output for real-time updates in UIs.\n",
      "\n",
      "---\n",
      "\n",
      "Would you like me to expand this into a **multi-agent system** (e.g., Researcher + Writer + Reviewer)? Or add web search using a tool?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Ya that's helpful. Maybe I'll \"\n",
    "                    \"build an autonomous agent with it!\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1930f39",
   "metadata": {},
   "source": [
    "## 3. Replay the full state history\n",
    "\n",
    "Now that you have added steps to the chatbot, you can replay the full state history to see everything that occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4594f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 5:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "305b3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chatbot',)\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f069082-f073-62c0-8005-7b2f410d031d'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7dca9",
   "metadata": {},
   "source": [
    "打印可以发现包括human，tool，assistant的消息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84b95b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "content='That’s a great idea! Building an autonomous agent with **LangGraph** is a fantastic way to explore its capabilities. You can create agents that **plan, execute tasks, use tools, and even collaborate** with other agents—all while maintaining state and supporting human oversight.\\n\\nHere’s a quick **example idea** to get you started:\\n\\n---\\n\\n### 🤖 **Autonomous Research Agent**\\nThis agent takes a research question (e.g., *\"What are the latest advancements in fusion energy?\"*), breaks it down into steps, searches the web, summarizes findings, and compiles a report.\\n\\n#### Key Components:\\n- **LLM Node**: For reasoning and planning.\\n- **Search Tool**: To fetch up-to-date information.\\n- **State Graph**: To manage flow between steps (plan → search → summarize → report).\\n- **Human-in-the-loop**: Optional approval before finalizing the report.\\n\\n---\\n\\n### 🔧 Simple LangGraph Skeleton (Python)\\n```python\\nfrom langgraph.graph import StateGraph, END\\nfrom langchain_core.messages import HumanMessage\\nfrom typing import TypedDict, Annotated\\nimport operator\\n\\n# Define the state\\nclass AgentState(TypedDict):\\n    task: str\\n    plan: str\\n    research_data: str\\n    report: str\\n    messages: Annotated[list, operator.add]\\n\\n# Initialize graph\\ngraph = StateGraph(AgentState)\\n\\n# Define nodes (e.g., planner, researcher, reporter)\\ndef plan_node(state):\\n    # Use LLM to generate a plan\\n    return {\"plan\": f\"Plan to research: {state[\\'task\\']}\"}\\n\\ndef research_node(state):\\n    # Call a search tool\\n    return {\"research_data\": \"Latest fusion energy breakthroughs in 2024...\"}\\n\\ndef write_report_node(state):\\n    # Generate report\\n    return {\"report\": f\"Report on {state[\\'task\\']}: {state[\\'research_data\\']}\"}\\n\\n# Add nodes\\ngraph.add_node(\"plan\", plan_node)\\ngraph.add_node(\"research\", research_node)\\ngraph.add_node(\"write_report\", write_report_node)\\n\\n# Set entry point\\ngraph.set_entry_point(\"plan\")\\n\\n# Define flow\\ngraph.add_edge(\"plan\", \"research\")\\ngraph.add_edge(\"research\", \"write_report\")\\ngraph.add_edge(\"write_report\", END)\\n\\n# Compile the graph\\napp = graph.compile()\\n\\n# Run!\\nresult = app.invoke({\\n    \"task\": \"fusion energy advancements\",\\n    \"messages\": [HumanMessage(content=\"Research fusion energy\")]\\n})\\n\\nprint(result[\"report\"])\\n```\\n\\n---\\n\\n### Tools You Might Integrate:\\n- **Tavily Search** (for up-to-date web results)\\n- **LangChain Tools** (APIs, databases, calculators)\\n- **Human Approval Node** (pause for review)\\n\\n---\\n\\nIf you\\'d like, I can help you **build this step by step**, add **streaming**, or even make **multiple agents collaborate** (e.g., one researcher, one critic).\\n\\nWant to start coding it together? 😊' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'} id='run--0fe41a6b-c6e7-4903-a3c6-28c5210b38e4-0'\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "content='That’s a great idea! Building an autonomous agent with **LangGraph** is a fantastic way to explore its capabilities. You can create agents that **plan, execute tasks, use tools, and even collaborate** with other agents.\\n\\nHere’s a quick roadmap to help you get started building your autonomous agent:\\n\\n---\\n\\n### 🚀 Step-by-Step: Build an Autonomous Agent with LangGraph\\n\\n#### 1. **Define the Goal**\\nDecide what your agent should do. For example:\\n- A **research agent** that answers questions by searching the web and summarizing results.\\n- A **task manager** that breaks down goals, assigns subtasks, and tracks progress.\\n- A **customer support bot** that routes issues and escalates when needed.\\n\\n---\\n\\n#### 2. **Set Up Your Environment**\\nInstall the required packages:\\n```bash\\npip install langgraph langchain langchain-openai\\n```\\n\\n> 💡 You’ll also need an API key from a provider like OpenAI, Anthropic, or Google.\\n\\n---\\n\\n#### 3. **Create a Simple Autonomous Agent (Example: Researcher)**\\n\\n```python\\nfrom langgraph.graph import StateGraph, MessagesState\\nfrom langchain_core.messages import HumanMessage\\nfrom langchain_openai import ChatOpenAI\\n\\n# Initialize LLM\\nllm = ChatOpenAI(model=\"gpt-4o\", api_key=\"your-openai-key\")\\n\\n# Define the agent\\'s logic\\ndef research_node(state: MessagesState):\\n    # Add a message to the state\\n    response = llm.invoke(state[\"messages\"])\\n    return {\"messages\": [response]}\\n\\n# Build the graph\\nworkflow = StateGraph(MessagesState)\\n\\n# Add nodes\\nworkflow.add_node(\"researcher\", research_node)\\n\\n# Set entry point\\nworkflow.set_entry_point(\"researcher\")\\n\\n# Add edges\\nworkflow.add_edge(\"researcher\", \"__end__\")\\n\\n# Compile the graph\\napp = workflow.compile()\\n\\n# Run the agent\\nresult = app.invoke({\\n    \"messages\": [HumanMessage(content=\"Summarize the latest AI trends in 2024\")]\\n})\\n\\nprint(result[\"messages\"][-1].content)\\n```\\n\\nThis creates a basic agent that takes a question and generates a response using an LLM.\\n\\n---\\n\\n#### 4. **Make It More Autonomous**\\nEnhance your agent by adding:\\n- **Tools**: Web search, database access, code execution.\\n- **Memory**: Persistent state across interactions.\\n- **Multiple Agents**: One for planning, one for research, one for writing.\\n- **Human-in-the-loop**: Approval steps before taking action.\\n\\n---\\n\\n#### 5. **Use LangGraph Platform (Optional)**\\nFor advanced use cases, check out the **LangGraph Platform**:\\n- [https://smith.langchain.com/langgraph](https://smith.langchain.com/langgraph)\\n- Offers **hosting, monitoring, and debugging** for your agents.\\n\\n---\\n\\n### 🔧 Tips\\n- Start small: Build a single-task agent first.\\n- Use `MessagesState` for chat-like workflows or define **custom state** for complex logic.\\n- Stream output for real-time updates in UIs.\\n\\n---\\n\\nWould you like me to expand this into a **multi-agent system** (e.g., Researcher + Writer + Reviewer)? Or add web search using a tool?' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'} id='run--07fb148f-1571-4847-897b-47146857db7f-0'\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "content=\"Ya that's helpful. Maybe I'll build an autonomous agent with it!\" additional_kwargs={} response_metadata={} id='8d5a15a3-57bb-47f2-b8c3-5559c0b88eb2'\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "content='LangGraph is a powerful library within the **LangChain ecosystem** designed to help developers build complex, stateful, and multi-agent AI applications by providing a structured framework for managing agent interactions and workflows.\\n\\n### Key Features of LangGraph:\\n\\n1. **Multi-Agent Coordination**  \\n   LangGraph enables the coordination of multiple LLM agents or chains, allowing them to work together in a defined sequence or parallel structure. This is useful for building applications like chatbots that handle diverse user requests or complex task-solving systems.\\n\\n2. **State Management**  \\n   It introduces the concept of **custom state**, which allows agents to maintain context across long-running workflows. This ensures reliability and helps keep agents on track during extended interactions.\\n\\n3. **Reliability & Control**  \\n   - Supports **moderation checks** to filter or validate agent outputs.\\n   - Enables **human-in-the-loop approvals**, giving developers control over critical decisions in the workflow.\\n\\n4. **Streaming Support**  \\n   Offers **first-class streaming** of tokens and intermediate steps, providing real-time visibility into agent reasoning and actions — ideal for responsive user interfaces.\\n\\n5. **Visual Workflow Design**  \\n   Workflows are represented as **directed graphs**, where nodes represent actions (like calling an LLM or tool) and edges define the flow of execution. This makes it easier to design, debug, and modify agent behavior.\\n\\n6. **Integration with LangChain**  \\n   Built on top of LangChain, it seamlessly integrates with existing tools, models, and memory systems, making it easy to extend existing applications.\\n\\n---\\n\\n### Use Cases:\\n- **Support Chatbots**: That route queries to specialized agents (e.g., billing, tech support).\\n- **Autonomous Agents**: Capable of planning, executing tasks, and collaborating.\\n- **Workflow Automation**: For processes requiring multiple steps, conditional logic, and external API calls.\\n\\n---\\n\\n### Learning Resources:\\n- [**LangGraph Tutorial – DataCamp**](https://www.datacamp.com/tutorial/langgraph-tutorial): A beginner-friendly introduction to LangGraph concepts and implementation.\\n- [**LangGraph Official Docs**](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/): Comprehensive guide covering basics, framework design, and platform features.\\n\\nWould you like a simple code example to get started with LangGraph?' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'} id='run--d41d327b-2ed9-4720-9715-385511acb1b6-0'\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "content='LangGraph is a powerful library within the **LangChain ecosystem** designed to help developers build complex, stateful, and multi-agent AI applications by providing a structured framework for managing agent interactions and workflows.\\n\\n### Key Features of LangGraph:\\n\\n1. **Multi-Agent Coordination**  \\n   LangGraph enables the coordination of multiple LLM agents or chains, allowing them to work together in a defined sequence or parallel structure. This is useful for building applications like chatbots that handle diverse user requests or complex task-solving systems.\\n\\n2. **State Management**  \\n   It introduces the concept of **custom state**, which allows agents to maintain context across long-running workflows. This ensures reliability and helps keep agents on track during extended interactions.\\n\\n3. **Reliability & Control**  \\n   - Supports **moderation checks** to filter or validate agent outputs.\\n   - Enables **human-in-the-loop approvals**, giving developers control over critical decisions in the workflow.\\n\\n4. **Streaming Support**  \\n   Offers **first-class streaming** of tokens and intermediate steps, providing real-time visibility into agent reasoning and actions — ideal for responsive user interfaces.\\n\\n5. **Visual Workflow Design**  \\n   Workflows are represented as **directed graphs**, where nodes represent actions (like calling an LLM or tool) and edges define the flow of execution. This makes it easier to design, debug, and modify agent behavior.\\n\\n6. **Integration with LangChain**  \\n   Built on top of LangChain, it seamlessly integrates with existing tools, models, and memory systems, making it easy to extend existing applications.\\n\\n---\\n\\n### Use Cases:\\n- **Support Chatbots**: That route queries to specialized agents (e.g., billing, tech support).\\n- **Autonomous Agents**: Capable of planning, executing tasks, and collaborating.\\n- **Workflow Automation**: For processes requiring multiple steps, conditional logic, and external API calls.\\n\\n---\\n\\n### Learning Resources:\\n- [**LangGraph Tutorial – DataCamp**](https://www.datacamp.com/tutorial/langgraph-tutorial): A beginner-friendly introduction to LangGraph concepts and implementation.\\n- [**LangGraph Official Docs**](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/): Comprehensive guide covering basics, framework design, and platform features.\\n\\nWould you like a simple code example to get started with LangGraph?' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'} id='run--d41d327b-2ed9-4720-9715-385511acb1b6-0'\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "content='{\"query\": \"LangGraph tutorial and overview\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"title\": \"LangGraph Tutorial: What Is LangGraph and How to Use It?\", \"content\": \"LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\", \"score\": 0.85097736, \"raw_content\": null}, {\"url\": \"https://langchain-ai.github.io/langgraph/concepts/why-langgraph/\", \"title\": \"Learn LangGraph basics - Overview\", \"content\": \"LangGraph  *   - [x]  LangGraph basics   LangGraph basics   *   Learn LangGraph basics *   - [x]  LangGraph framework   LangGraph framework   *   - [x]  LangGraph Platform   LangGraph Platform   *   Learn LangGraph basics LangGraph is built for developers who want to build powerful, adaptable AI agents. *   **Reliability and controllability.** Steer agent actions with moderation checks and human-in-the-loop approvals. LangGraph persists context for long-running workflows, keeping your agents on course. *   **First-class streaming support.** With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time. 4.   Add human-in-the-loop controls In completing this series of tutorials, you will build a support chatbot in LangGraph that can: *   ✅ **Use custom state** to control its behavior \", \"score\": 0.81097376, \"raw_content\": null}], \"response_time\": 1.5}' name='tavily_search' id='8fa004ac-b2db-4e9c-a1d6-359a99febd16' tool_call_id='call_6890d74c9e174ffc9a54b0'\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_6890d74c9e174ffc9a54b0', 'function': {'arguments': '{\"query\": \"LangGraph tutorial and overview\"}', 'name': 'tavily_search'}, 'type': 'function'}]} response_metadata={'finish_reason': 'tool_calls', 'model_name': 'qwen-plus-latest'} id='run--21d70965-1925-4ead-8825-c8f792af4018-0' tool_calls=[{'name': 'tavily_search', 'args': {'query': 'LangGraph tutorial and overview'}, 'id': 'call_6890d74c9e174ffc9a54b0', 'type': 'tool_call'}]\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "content=\"I'm learning LangGraph. Could you do some research on it for me?\" additional_kwargs={} response_metadata={} id='a611236a-04c8-4cc5-8149-3f99260abcf0'\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values['messages']):\n",
    "        print(state.values[\"messages\"][-1])\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fceccb",
   "metadata": {},
   "source": [
    "## 4. Load a state from a moment-in-time¶\n",
    "\n",
    "The checkpoint's to_replay.config contains a checkpoint_id timestamp. Providing this checkpoint_id value tells LangGraph's checkpointer to load the state from that moment in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0b1fb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That’s a fantastic idea! Building an **autonomous agent** with LangGraph is a great way to explore its full potential. You can create agents that **plan, execute, adapt, and even collaborate** with other agents to achieve complex goals.\n",
      "\n",
      "Here’s a quick roadmap to help you get started:\n",
      "\n",
      "---\n",
      "\n",
      "### 🚀 Step-by-Step: Build an Autonomous Agent with LangGraph\n",
      "\n",
      "#### 1. **Define the Goal**\n",
      "Pick a use case:\n",
      "- A **research agent** that searches the web, summarizes articles, and compiles reports.\n",
      "- A **personal task assistant** that manages your to-dos, schedules meetings, and sends emails.\n",
      "- A **customer support bot** that routes issues and escalates when needed.\n",
      "\n",
      "#### 2. **Design the Workflow (Graph)**\n",
      "Use a **stateful graph** where each node is an action:\n",
      "- `planning` → `researching` → `validating` → `reporting`\n",
      "- Add conditional edges (e.g., “if info is insufficient, loop back to research”).\n",
      "\n",
      "#### 3. **Set Up State Management**\n",
      "Define a **custom state schema** (e.g., using Pydantic) to track:\n",
      "```python\n",
      "class AgentState(TypedDict):\n",
      "    task: str\n",
      "    plan: str\n",
      "    research_data: list\n",
      "    report: str\n",
      "    revision_needed: bool\n",
      "```\n",
      "\n",
      "#### 4. **Integrate Tools**\n",
      "Give your agent tools like:\n",
      "- Web search (Tavily, Google)\n",
      "- Code interpreter\n",
      "- Database access\n",
      "- Email/SMS APIs\n",
      "\n",
      "LangGraph lets you plug these in easily via LangChain tools.\n",
      "\n",
      "#### 5. **Add Human-in-the-Loop (Optional)**\n",
      "Pause execution for approval:\n",
      "```python\n",
      "def needs_human_review(state):\n",
      "    return \"YES\" if state[\"revision_needed\"] else \"NO\"\n",
      "```\n",
      "\n",
      "#### 6. **Stream & Monitor**\n",
      "Use LangGraph’s streaming to watch the agent think and act in real time — perfect for debugging and UX.\n",
      "\n",
      "---\n",
      "\n",
      "### 🔧 Example: Simple Research Agent (Conceptual)\n",
      "\n",
      "```python\n",
      "from langgraph.graph import StateGraph, END\n",
      "\n",
      "# Define nodes\n",
      "def plan_task(state):\n",
      "    # Use LLM to generate a plan\n",
      "    return {\"plan\": llm(f\"Plan steps for: {state['task']}\")}\n",
      "\n",
      "def do_research(state):\n",
      "    # Use a search tool\n",
      "    results = search_tool.invoke(state[\"plan\"])\n",
      "    return {\"research_data\": results}\n",
      "\n",
      "def write_report(state):\n",
      "    # Generate report\n",
      "    report = llm(f\"Write report based on: {state['research_data']}\")\n",
      "    return {\"report\": report}\n",
      "\n",
      "# Build graph\n",
      "workflow = StateGraph(AgentState)\n",
      "\n",
      "workflow.add_node(\"plan\", plan_task)\n",
      "workflow.add_node(\"research\", do_research)\n",
      "workflow.add_node(\"write\", write_report)\n",
      "\n",
      "workflow.set_entry_point(\"plan\")\n",
      "workflow.add_edge(\"plan\", \"research\")\n",
      "workflow.add_edge(\"research\", \"write\")\n",
      "workflow.add_edge(\"write\", END)\n",
      "\n",
      "app = workflow.compile()\n",
      "\n",
      "# Run\n",
      "result = app.invoke({\"task\": \"Research the benefits of solar energy\"})\n",
      "print(result[\"report\"])\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 📚 Resources to Keep Going:\n",
      "- [LangGraph Docs](https://langchain-ai.github.io/langgraph/)\n",
      "- [LangChain + LangGraph YouTube Tutorials](https://www.youtube.com/results?search_query=LangGraph+tutorial)\n",
      "- [GitHub Examples](https://github.com/langchain-ai/langgraph)\n",
      "\n",
      "If you'd like, I can help you scaffold a full project or integrate specific tools (like search, memory, or APIs). Just say the word! 💡\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
