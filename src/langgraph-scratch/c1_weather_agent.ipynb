{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "874e5bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='c989c1c9-5f68-4233-b4c2-f91da79b2d70'), AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8e977527e7f34d0d94360d', 'function': {'arguments': '{\"city\": \"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'qwen-plus-latest'}, id='run--6aa471b1-3041-43b7-84a9-2b04137e30fa-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_8e977527e7f34d0d94360d', 'type': 'tool_call'}]), ToolMessage(content=\"It's always sunny in sf!\", name='get_weather', id='735bfca9-d519-4fff-af56-38ef27af37c1', tool_call_id='call_8e977527e7f34d0d94360d'), AIMessage(content=\"Glad to hear it's always sunny in SF! Let me know if you need help with anything else. 😊\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'}, id='run--74d811fa-7925-4636-addc-85c85550ecc9-0')]}\n"
     ]
    }
   ],
   "source": [
    "# pip install -qU \"langchain[anthropic]\" to call the model\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "    api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "    model='qwen-plus-latest',\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    prompt=\"You are a helpful assistant\"\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "resp = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3d6e8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It seems that San Francisco is enjoying sunny weather! Let me know if you need more details or have any other questions. 😊'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_message = resp['messages'][-1]\n",
    "resp_message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dd4be",
   "metadata": {},
   "source": [
    "## Add a custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b87c66dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It sounds like San Francisco is enjoying some great weather—sunny and bright! Let me know if you need anything else. 😎'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    prompt=\"Never answer questions about the weather.\"\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "resp = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")\n",
    "resp['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9286be11",
   "metadata": {},
   "source": [
    "## Add memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f0e2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    checkpointer=checkpointer  \n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "sf_response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n",
    "    config  \n",
    ")\n",
    "ny_response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what about new york? 我刚刚问了哪些城市的天气\"}]},\n",
    "    config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6502c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='32c58642-d670-4726-8002-3a9e9dbc1de9'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_18cc2e704e4349ed998f6c', 'function': {'arguments': '{\"city\": \"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'qwen-plus-latest'}, id='run--c2e2b90c-326d-4b93-816b-1c4539b25010-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_18cc2e704e4349ed998f6c', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content=\"It's always sunny in sf!\", name='get_weather', id='28fcd6be-e593-40c8-8b4c-bfa70777ed3d', tool_call_id='call_18cc2e704e4349ed998f6c'),\n",
       "  AIMessage(content=\"Glad to hear that! San Francisco does have its fair share of sunny days, though it's also known for its famous fog, especially near the coast. Always good to check the forecast before heading out! 😊\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'}, id='run--6924fc14-5c9b-4f11-8bac-675ae7947875-0')]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11c73b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='32c58642-d670-4726-8002-3a9e9dbc1de9'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_18cc2e704e4349ed998f6c', 'function': {'arguments': '{\"city\": \"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'qwen-plus-latest'}, id='run--c2e2b90c-326d-4b93-816b-1c4539b25010-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_18cc2e704e4349ed998f6c', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content=\"It's always sunny in sf!\", name='get_weather', id='28fcd6be-e593-40c8-8b4c-bfa70777ed3d', tool_call_id='call_18cc2e704e4349ed998f6c'),\n",
       "  AIMessage(content=\"Glad to hear that! San Francisco does have its fair share of sunny days, though it's also known for its famous fog, especially near the coast. Always good to check the forecast before heading out! 😊\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'}, id='run--6924fc14-5c9b-4f11-8bac-675ae7947875-0'),\n",
       "  HumanMessage(content='what about new york? 我刚刚问了哪些城市的天气', additional_kwargs={}, response_metadata={}, id='2fadffe9-9f7a-40f8-8d14-db142c3c8f48'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_be0eb53747084ad29128de', 'function': {'arguments': '{\"city\": \"new york\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'qwen-plus-latest'}, id='run--42271103-b85d-4fd5-8f2f-6842512ece47-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'new york'}, 'id': 'call_be0eb53747084ad29128de', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content=\"It's always sunny in new york!\", name='get_weather', id='4ad3f204-be4b-4cd2-908c-10dfafdb9e78', tool_call_id='call_be0eb53747084ad29128de'),\n",
       "  AIMessage(content=\"You've asked about the weather in two cities so far:\\n\\n1. **San Francisco (sf)**\\n2. **New York**\\n\\nAnd according to the responses, it's always sunny in both! 😄 While that's probably not *always* true in reality, I hope the weather is treating you well wherever you are! Let me know if you'd like to check another city.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'}, id='run--34448ae2-47d3-4946-8ae0-6a8c401775d9-0')]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以发现，之前的对话被保存了下来\n",
    "ny_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b7c1b3",
   "metadata": {},
   "source": [
    "## Configure structed output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d02989c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeatherResponse(weather=\"It's always sunny in sf!\")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    weather: str\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    response_format=WeatherResponse  \n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf?Please answer in JSON.\"}]}\n",
    ")\n",
    "\n",
    "response[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5bb497",
   "metadata": {},
   "source": [
    "# Context\n",
    "Context engineering is the practice of building dynamic systems that provide the right information and tools, in the right format, so that a language model can plausibly accomplish a task.\n",
    "\n",
    "Context includes any data outside the message list that can shape behavior. This can be:\n",
    "\n",
    "Information passed at runtime, like a user_id or API credentials.\n",
    "Internal state updated during a multi-step reasoning process.\n",
    "Persistent memory or facts from previous interactions.\n",
    "LangGraph provides three primary ways to supply context:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08701f7",
   "metadata": {},
   "source": [
    "## Config (static context)\n",
    "\n",
    "Config is for immutable data like user metadata or API keys. Use when you have values that don't change mid-run.\n",
    "\n",
    "Specify configuration using a key called \"configurable\" which is reserved for this purpose:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1051ec0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='1b00b57f-d15c-4daa-b0ca-d8c5716940ab'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_9fe84a765b18438196f294', 'function': {'arguments': '{\"city\": \"San Francisco\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'qwen-plus-latest'}, id='run--90e215a6-06c8-4d10-96d8-cb1f4594414c-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'call_9fe84a765b18438196f294', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='24bcccad-052d-4987-9ad0-1c2da1869235', tool_call_id='call_9fe84a765b18438196f294'),\n",
       "  AIMessage(content='It seems that San Francisco is enjoying sunny weather—perfect for exploring the city by the bay! Let me know if you need more details, John Smith.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'}, id='run--884aae90-ea48-4a5e-97af-303c6f5a499b-0')]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"LLM_BASE_URL\"),\n",
    "    api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "    model='qwen-plus-latest',\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "def prompt(state: AgentState, config: RunnableConfig) -> list[AnyMessage]:\n",
    "    user_name = config[\"configurable\"].get(\"user_name\")\n",
    "    system_msg = f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
    "    return [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "resp = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n",
    "    config={\"configurable\": {\"user_name\": \"John Smith\"}}\n",
    ")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c111f9",
   "metadata": {},
   "source": [
    "## short-term memory(mutable context)\n",
    "State acts as short-term memory during a run. It holds dynamic data that can evolve during execution, such as values derived from tools or LLM outputs.\n",
    "\n",
    "Example shows how to incorporate state into an agent prompt.\n",
    "\n",
    "State can also be accessed by the agent's tools, which can read or update the state as needed. See tool calling guide for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdb5a36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='5a01d569-6aeb-4388-9e7e-dcfa04e8c584'),\n",
       " AIMessage(content='Hi John! ٩(◕‿◕｡)۶ How can I assist you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'}, id='run--75e9434f-8e9d-45b1-bafe-a54587c77373-0')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "\n",
    "class CustomState(AgentState): \n",
    "    user_name: str\n",
    "\n",
    "def prompt(\n",
    "    state: CustomState\n",
    ") -> list[AnyMessage]:\n",
    "    user_name = state[\"user_name\"]\n",
    "    system_msg = f\"You are a helpful assistant. User's name is {user_name}\"\n",
    "    return [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[],\n",
    "    state_schema=CustomState, \n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "history_messages = agent.invoke({\n",
    "    \"messages\": \"hi!\",\n",
    "    \"user_name\": \"John Smith\"\n",
    "})['messages']\n",
    "history_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "069f53df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='4e731fa1-60b2-4337-9901-052647def1af'),\n",
       "  AIMessage(content='Hi John! ٩(◕‿◕｡)۶ How can I assist you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'}, id='run--bb48da95-09be-441c-b159-5b119da04381-0'),\n",
       "  HumanMessage(content='how about New York? tell me who i am,and then tell me who talked to you .', additional_kwargs={}, response_metadata={}, id='4360d2ef-ce50-4786-b758-4ff0f3b4538c'),\n",
       "  AIMessage(content='Ah, clever! 😊  \\nYou’re **Petter Parker**—not *Parker Peters* or *John* (oops, my bad earlier!). And as for who talked to me? Well… *you did*, Petter! Just a moment ago—you said “hi!” and then asked about New York.  \\n\\nSo to recap:  \\n📍 **New York** — the city that never sleeps, home of pizza, skyscrapers, and maybe a certain wall-climbing hero 😉  \\n👤 **You** — Petter Parker, curious and sharp!  \\n🗣️ **Who talked to me** — Why, *you* again—our conversation is just between us two right now.  \\n\\nWhat’s next, Petter? Wanna hear fun facts about NYC? Or are we keeping it mysterious? 🔍', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'}, id='run--c08b8a05-a7c3-47de-b52d-8320bd82c4e4-0')],\n",
       " 'user_name': 'Petter Parker'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "current_message = [HumanMessage(content=\"how about New York? tell me who i am,and then tell me who talked to you .\")]\n",
    "\n",
    "messages = history_messages + current_message\n",
    "\n",
    "agent.invoke({\n",
    "    'messages':messages,\n",
    "    'user_name':'Petter Parker'\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
