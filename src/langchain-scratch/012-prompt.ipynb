{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt\n",
    "## PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daijunjie/miniconda3/envs/langchain-env/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a funny joke about robots.\n",
      "text='Tell me a funny joke about robots.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me a funny joke about robots.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Simple prompt with placeholders\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "# Filling placeholders to create a prompt\n",
    "filled_prompt = prompt_template.format(adjective=\"funny\", content=\"robots\")\n",
    "print(filled_prompt)\n",
    "filled_prompt = prompt_template.invoke({\"adjective\":\"funny\", \"content\":\"robots\"})\n",
    "print(filled_prompt)\n",
    "filled_prompt.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You are a helpful AI bot. Your name is Alice.' additional_kwargs={} response_metadata={}\n",
      "content='Hello, how are you doing?' additional_kwargs={} response_metadata={}\n",
      "content=\"I'm doing well, thanks!\" additional_kwargs={} response_metadata={}\n",
      "content='What is the meaning of life?' additional_kwargs={} response_metadata={}\n",
      "[SystemMessage(content='You are a helpful AI bot. Your name is Alice.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the meaning of life?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts  import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ])\n",
    "\n",
    "formatted_messages = chat_template.format_messages(name=\"Alice\", user_input=\"What is the meaning of life?\")\n",
    "\n",
    "for message in formatted_messages:\n",
    "    print(message)\n",
    "    # print(message.model_construct())\n",
    "print(formatted_messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\\n  \"birthdate\": \"June 28, 1971\",\\n  \"birthplace\": \"Pretoria, South Africa\"\\n}' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwq-plus-latest'} id='run--951faa7d-1365-4c45-9de9-1909c32be5af-0'\n"
     ]
    }
   ],
   "source": [
    "from demo1 import get_model\n",
    "model = get_model()\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with `birthdate` and `birthplace` key that answers the following question: {question}\"\n",
    ")\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "json_chain = json_prompt | model | json_parser\n",
    "\n",
    "result_list = list(json_chain.stream({\"question\": \"When and where was Elon Musk born?\"}))[-1]\n",
    "print(result_list)\n",
    "\n",
    "# chain = json_prompt | model\n",
    "# output = chain.invoke(\"When and where was Elon Musk born?\")\n",
    "# print(output.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CommaSeparatedListParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manchester United, Manchester City, Liverpool, Chelsea, Arsenal\n",
      "['Manchester United', 'Manchester City', 'Liverpool', 'Chelsea', 'Arsenal']\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from demo1 import get_model\n",
    "model = get_model()\n",
    "\n",
    "# Initialize output parser\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "# Create format instructions\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Create a prompt to request a list\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    # input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "# Define a query to prompt the model\n",
    "query = \"English Premier League Teams\"\n",
    "# Generate the output\n",
    "output = model.invoke(prompt.format(subject=query)).content\n",
    "print(output)\n",
    "parsed_result = output_parser.parse(output)\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chain版本的CommaSeparatedListParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  ['Manchester United', 'Manchester City', 'Liverpool', 'Chelsea', 'Arsenal']\n",
      "type:  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from demo1 import get_model\n",
    "model = get_model()\n",
    "\n",
    "# Initialize output parser\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "# Create format instructions\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Create a prompt to request a list\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    # input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "# Define a query to prompt the model\n",
    "query = \"English Premier League Teams\"\n",
    "# build the chain\n",
    "chain = prompt | model | output_parser\n",
    "# Run the chain 不用手动执行parse操作\n",
    "output = chain.invoke({\"subject\": query})\n",
    "print('output: ', output)\n",
    "print('type: ', type(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw output: 1969-07-20T20:17:40.000000Z \n",
      "\n",
      "1969-07-20 20:17:40\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from demo1 import get_model\n",
    "\n",
    "model = get_model()\n",
    "# Initialize the DatetimeOutputParser\n",
    "output_parser = DatetimeOutputParser()\n",
    "\n",
    "# Create a prompt with format instructions\n",
    "template = \"\"\"\n",
    "Answer the user's question:\n",
    "{question}\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "query = \"when did Neil Armstrong land on the moon in terms of GMT?\"\n",
    "\n",
    "# Run the chain\n",
    "output = chain.run(query)\n",
    "print('raw output:', output, '\\n')\n",
    "# Parse the output using the datetime parser\n",
    "parsed_result = output_parser.parse(output)\n",
    "\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
